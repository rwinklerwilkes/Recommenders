{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import csc_matrix, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movielens(mean_adjust = 'user'):\n",
    "    '''Loads movielens set into a Dataframe. Adjusted rating is user by default'''\n",
    "    path = 'ml-latest-small\\\\'\n",
    "    df = pd.read_csv(path + 'ratings.csv')\n",
    "    movie_xref = pd.read_csv(path + 'movies.csv')\n",
    "    users = df.groupby('userId').mean()['rating'].reset_index()\n",
    "    users['user_mean_rating'] = users['rating']\n",
    "    users['uid'] = users.index\n",
    "    users.drop('rating',inplace=True,axis=1)\n",
    "    df = df.merge(users,left_on='userId',right_on='userId')\n",
    "    movies = df.groupby('movieId').mean()['rating'].reset_index()\n",
    "    movies['movie_mean_rating'] = movies['rating']\n",
    "    movies = movies.merge(movie_xref,left_on='movieId',right_on='movieId')\n",
    "    movies.drop('rating',inplace=True,axis=1)\n",
    "    movies['mid'] = movies.index\n",
    "    df = df.merge(movies,left_on='movieId',right_on='movieId')\n",
    "    if mean_adjust == 'user':\n",
    "        df['adjusted_rating'] = df['rating'] - df['user_mean_rating']\n",
    "    elif mean_adjust == 'movie':\n",
    "        df['adjusted_rating'] = df['rating'] - df['movie_mean_rating']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_movielens()\n",
    "users_list = df['uid']\n",
    "movies_list = df['mid']\n",
    "ratings_list = df['rating']\n",
    "df_sparse = csr_matrix((ratings_list,(users_list,movies_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priors(df):\n",
    "    m_ct = df.groupby('mid').count()['uid'].reset_index()\n",
    "    mr_ct = df.groupby(['mid','rating']).count()['uid'].reset_index()\n",
    "    total_ct = m_ct.merge(mr_ct,left_on='mid',right_on='mid')\n",
    "    total_ct['prob'] = total_ct['uid_y']/total_ct['uid_x']\n",
    "    return total_ct[['mid','rating','prob']]\n",
    "\n",
    "def calculate_priors_sparse(df_sparse,laplacian = None):\n",
    "    '''laplacian should be a floating point'''\n",
    "    '''This takes a sparse matrix which has as columns the set of items to be rated'''\n",
    "    '''The rows are each one user.'''\n",
    "    '''Nonzero entries are ratings of items they have rated'''\n",
    "    \n",
    "    num_cols = df_sparse.shape[1]\n",
    "    all_ratings = list(set(df_sparse.data))\n",
    "    all_ratings = all_ratings\n",
    "    all_ratings = sorted(all_ratings)\n",
    "    num_ratings = len(all_ratings)\n",
    "    ct_df = np.zeros((num_cols,num_ratings))\n",
    "\n",
    "    for c in range(num_cols):\n",
    "        #counts the number of unique ratings (per column) and how many times that rating occurred\n",
    "        unq,cts = np.unique(df_sparse[:,c].toarray(),return_counts=True)\n",
    "        d = dict(zip(unq, cts))\n",
    "        d = {k:v for k,v in d.items() if k > 0}\n",
    "        rating_dict = {rating:0 for rating in all_ratings}\n",
    "        for k,v in d.items():\n",
    "            rating_dict[k] = v\n",
    "        #d = {k:v for k,v in d.items() if k!=0}\n",
    "        ct_df[c] = [i[1] for i in sorted(rating_dict.items(),key=lambda x: x[0])]\n",
    "    #This dataframe now has rows which are films, columns which are ratings, and each entry has the number of times\n",
    "    #which that particular rating occurred for that particular film\n",
    "    ct_df = pd.DataFrame(ct_df)\n",
    "    ct_df.columns = all_ratings\n",
    "    numerator_cols = ct_df.columns\n",
    "    ct_df['rowsum'] = ct_df.sum(axis=1)\n",
    "\n",
    "    if laplacian is not None:\n",
    "        ct_df[numerator_cols] = ct_df[numerator_cols].fillna(0) + laplacian\n",
    "        ct_df['rowsum'] = ct_df['rowsum'].fillna(0) + laplacian * len(numerator_cols)\n",
    "    ct_df = ct_df.apply(lambda x: x/x.rowsum,axis=1)\n",
    "    ct_df = ct_df.drop('rowsum',axis=1)\n",
    "    ct_df = ct_df.unstack().reset_index()\n",
    "    ct_df.columns = ['rating','mid','prob']\n",
    "    return ct_df\n",
    "\n",
    "#Will need to fix this similarly to the above\n",
    "def calculate_conditional(df,rating_vs,rating_k,j,k,laplacian = None):\n",
    "    '''\n",
    "    df is the sparse dataframe containing the data to be trained/rated\n",
    "    rating_vs is the rating that we're comparing against for the conditional - \n",
    "        P(r_uk | r_uj = v_s), what's the likelihood that we observed rating r_uk for item k (user u) given that\n",
    "        user u gave item j the rating v_s\n",
    "    '''\n",
    "    total_users = df.shape[0]\n",
    "    df_j = df[:,j]\n",
    "    #Find set of users who rated item j rating\n",
    "    users = (df_j == rating_vs).nonzero()[0]\n",
    "    num_users = len(users)\n",
    "    #Of those users, how many rated item k the same as the original user?\n",
    "    df_k = df_sparse[users,k]\n",
    "    nz = df_k.nonzero()\n",
    "    nzk = df_k[nz[0]].toarray()\n",
    "    unq,cts = np.unique(nzk,return_counts=True)\n",
    "    ct = []\n",
    "\n",
    "    d = dict(zip(unq, cts))\n",
    "    d = {k:v for k,v in d.items() if k!=0}\n",
    "    ct.append(d)\n",
    "    #This dataframe now has rows which are films, columns which are ratings, and each entry has the number of times\n",
    "    #which that particular rating occurred for that particular film\n",
    "    ct_df = pd.DataFrame(ct)\n",
    "    numerator_cols = ct_df.columns\n",
    "    ct_df['rowsum'] = ct_df.sum(axis=1)\n",
    "\n",
    "    if laplacian is not None:\n",
    "        ct_df[numerator_cols] = ct_df[numerator_cols].fillna(0) + laplacian\n",
    "        ct_df['rowsum'] = ct_df['rowsum'].fillna(0) + laplacian * total_users\n",
    "    try:\n",
    "        retval = (ct_df[rating_vs].values/ct_df['rowsum'].values)[0]\n",
    "    except:\n",
    "        retval = 1/total_users\n",
    "    return retval\n",
    "    \n",
    "def calculate_rating(df,user,item,laplacian = None):\n",
    "    '''\n",
    "    df: sparse array (csc?) containing the data to be predicted\n",
    "    user is index of user to look at\n",
    "    item is item to be rated\n",
    "    \n",
    "    for all items that the user rated, we need to see, for each rating possible to use,\n",
    "    what the likelihood is that user rated item, that rating. In order to do so, we use the formula:\n",
    "    \n",
    "    P(r_uj = v_s | Observed ratings of user u) is proportional to P(r_uj = v_s) * PI(P(r_uk | r_uj = v_s) for k in I_u)\n",
    "    Where I_u is the set of items that user u has rated\n",
    "    P(r_uj = vs) is called the prior probability, and we'll need to calculate that for each item first\n",
    "    P(r_uk | r_uj = v_s) is called the conditional probability.\n",
    "    '''\n",
    "    \n",
    "    #priors contains the prior probabilities for all items\n",
    "    #for a given item, it's the list of all ratings and what ratio, \n",
    "    #for each rating for that item, what was the likelihood it occurred\n",
    "    priors = calculate_priors_sparse(df,laplacian = laplacian)\n",
    "    vals = list(set(df.data))\n",
    "    num = 0\n",
    "    denom = 0\n",
    "    user_items = df[user,:].nonzero()[1]\n",
    "    for i in range(len(vals)):\n",
    "        vs = vals[i]\n",
    "        try:\n",
    "            prior = priors.loc[(priors['mid']==item)&(priors['rating']==vs),'prob'].values[0]\n",
    "        except:\n",
    "            prior = 0\n",
    "            continue\n",
    "        mult = 1\n",
    "        for k in user_items:\n",
    "            user_rating = df[user,k]\n",
    "            conditional = calculate_conditional(df,vs,user_rating,item,k,laplacian = laplacian)\n",
    "            mult = mult * conditional \n",
    "            if np.isnan(conditional or np.isnan(prior)):\n",
    "                print('vs: %0.3f rating: %0.3f item: %i k: %i')\n",
    "        num += vs*prior*mult\n",
    "        denom += prior * mult\n",
    "    return num/denom\n",
    "\n",
    "def print_user_movies(df,user):\n",
    "    movies = df.loc[df['uid']==user,'title']\n",
    "    print(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "    [1,-1,1,-1,1,-1],\n",
    "    [1,1,0,-1,-1,-1],\n",
    "    [0,1,1,-1,-1,0],\n",
    "    [-1,-1,-1,1,1,1],\n",
    "    [-1,0,-1,1,1,1]\n",
    "]\n",
    "test_array = np.array(test)\n",
    "test_sparse = csc_matrix(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = calculate_priors_sparse(df_sparse,laplacian=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.98558709162\n"
     ]
    }
   ],
   "source": [
    "r = calculate_rating(df_sparse,2,1,laplacian = 0.8)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00000000244\n"
     ]
    }
   ],
   "source": [
    "r = calculate_rating(df_sparse,2,321,laplacian=0.8)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.99619678703\n"
     ]
    }
   ],
   "source": [
    "r = calculate_rating(df_sparse,2,595,laplacian=0.8)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.66251781122\n"
     ]
    }
   ],
   "source": [
    "r = calculate_rating(df_sparse,580,1,laplacian=0.8)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_factors(df_sparse,num_factors):\n",
    "    '''Constructs the num_factors user factors and item factors for the sparse matrix'''\n",
    "    m = df_sparse.shape[0]\n",
    "    n = df_sparse.shape[1]\n",
    "    U = np.random.rand(m,num_factors)\n",
    "    V = np.random.rand(n,num_factors)\n",
    "    return U,V\n",
    "\n",
    "def error(df_sparse,U,V):\n",
    "    '''Calculates the matrix portion of the error term'''\n",
    "    d = df_sparse.nonzero()\n",
    "    rows = d[0].reshape(1,-1).flatten()\n",
    "    cols = d[1].reshape(1,-1).flatten()\n",
    "    e = df_sparse[d] - np.matmul(U,V.T)[d]\n",
    "    e = np.asarray(e).flatten()\n",
    "    e = csc_matrix((e,(rows,cols)))\n",
    "    return e\n",
    "\n",
    "def frobenius_norm(df_sparse,U,V):\n",
    "    e = error(df_sparse,U,V)\n",
    "    e = e.power(2)\n",
    "    return e.sum()\n",
    "\n",
    "def cost_function(df_sparse,U,V,l):\n",
    "    '''Calculates the cost function to minimize, l is the regularization term'''\n",
    "    e = frobenius_norm(df_sparse,U,V)\n",
    "    usum = np.square(U).sum()\n",
    "    vsum = np.square(V).sum()\n",
    "    J = 0.5 * e + (l/2)*usum + (l/2)*vsum\n",
    "    return J\n",
    "\n",
    "def update_factors(df_sparse,U,V,l,alpha):\n",
    "    '''alpha is learning rate, l is regularization parameter'''\n",
    "    nz = df_sparse.nonzero()\n",
    "    E = error(df_sparse,U,V)\n",
    "    U_temp = U*(1-alpha * l) + alpha * (E * V)\n",
    "    V_temp = V*(1-alpha * l) + alpha * (E.T * U)\n",
    "    return U_temp,V_temp\n",
    "\n",
    "def fit(df_sparse,num_factors,learning_rate,regularization_rate):\n",
    "    U,V = construct_factors(df_sparse,num_factors)\n",
    "    J = cost_function(df_sparse,U,V,regularization_rate)\n",
    "    prev = J\n",
    "    iter_ctr = 0\n",
    "    while True:\n",
    "        iter_ctr += 1\n",
    "        U,V = update_factors(df_sparse,U,V,regularization_rate,learning_rate)\n",
    "        J = cost_function(df_sparse,U,V,regularization_rate)\n",
    "        pct_change = J/prev-1\n",
    "        if abs(pct_change) < 0.001 or iter_ctr > 1000:\n",
    "            break\n",
    "        prev = J\n",
    "    return U,V\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,V = fit(df_sparse,10,0.0001,0.8)\n",
    "pred_rat = np.matmul(U,V.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = error(df_sparse,U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "0.0479521599001\n",
      "2.4520478401\n"
     ]
    }
   ],
   "source": [
    "print(df_sparse[0,30])\n",
    "print(e[0,30])\n",
    "print(pred_rat[0,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54999.428332574898"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_function(df_sparse,U,V,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = error(df_sparse,U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
